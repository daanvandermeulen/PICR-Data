library("writexl")
#######FIGURE OUT WHO STAYS#######
colnames(fsir4w)
colnames(fsir4w)[61] <- "Age2"
colnames(fsir4w)[62] <- "Sex2"
colnames(fsir4w)[63] <- "Region2"
colnames(fsir4w)[64] <- "MaritalS2"
colnames(fsir4w)[66] <- "Edu2"
colnames(fsir4w)[67] <- "Income2"
colnames(fsir4w)[68] <- "NewsConsumption2"
colnames(fsir4w)[69] <- "PoliticalInterest2"
colnames(fsir4w)[70] <- "relig2"
colnames(fsir4w)[71] <- "PolOr2"
fsir7.1 <- subset(fsir4w[, c(9:27, 29:71, 74:75)])
fsir7.1 <- fsir7.1[!duplicated(fsir7.1$userID),]
fsir7.1$careless2 <- longstring(fsir7.1)
```
```{r merge of both files}
#export datasets
library(rio)
library(foreign)
library(datasets)
collect1 <- merge(fsir6, fsir7.1, by = "userID")
collect1 <- collect1[!duplicated(collect1$userID),]
collect1 <- subset(collect1, userID!="")
```
```{r export}
toremove <- grep("^collect1", ls(),
invert = TRUE,
value = TRUE)
rm(list = c(toremove, "toremove"))
#export(collect1, "C:/Everything R/DATA TRIALS - FSIR/Replication materials/REP/check #knit/collect1.recon24112022.sav")
```
##fsir_cleaning - first collection
```{r 2setup, include=FALSE}
cat ("\014")    #clean the R console
#import file named fsir from computer into R. The file already has meaningful
#names, scales were checked, and all unnecessary vars were removed.
library(rio)
library(foreign)
#fsir <- read_sav("Data/lfsira.sav")
fsir <- import("C:/Everything R/DATA TRIALS - FSIR/Effects of Framing Counter Stereotypes - Replication Materials/r-project-template-based/Suprise Experiments/Data/lfsira.sav",
to.data.frame = TRUE, stringsAsFactors = TRUE, header = TRUE)
#change name of Denial_5, which is an attention check item,
#if the name bothers you.
library(plyr)
colnames(fsir)
fsir <- plyr::rename(fsir, replace =
c("Denial_5" = "attcheck"))
fsir <- subset(fsir, select = -c(3:4, 7:17, 107:197))
names(fsir)
#check names again to see renaming worked.
knitr::opts_chunk$set(echo = TRUE)
```
```{r 2cleaning 1}
#this is for cleaning out all participants who faild attention check on the
#first wave of quesionnaire.
#basically if participants answered anything but 4 on this attcheck item,
#they failed and should be removed.
#make subset to continue working.
fsir1 <- subset(fsir, attcheck==4)
#from now on, all code would deal with fsir1, until another subset is created.
```
```{r 2cleaning 2}
#this is the code to detect those who took too long or too little time.
colnames(fsir1)
class(fsir1$Duration__in_seconds_)
#the var is already numeric, which is what we need to proceed. if for some
#reason it isn't, use the code below by removing the # sign.
#pisrSub[4] <- lapply(pisrSub[3], as.numeric) #make the duration numeric
fsir1$DuraMin <- fsir1$Duration__in_seconds_/60
#make the duration in minutes
#see the mean time of taking the survey to determine the cut-off.
mean(fsir1$DuraMin)
median(fsir1$DuraMin)
#function for getting mode:
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
getmode(fsir1$DuraMin)
sd(fsir1$DuraMin, na.rm = TRUE)
#identify outliers based on time of response and careless long answers.
boxplot(fsir1$DuraMin)$out
Q <- quantile(fsir1$DuraMin, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(fsir1$DuraMin)
up <-  Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Rangeï»¿
fsir1.1 <- subset(fsir1, fsir1$DuraMin > (Q[1] - 1.5*iqr) & fsir1$DuraMin < (Q[2]+1.5*iqr))
```
```{r 2cleaning 3}
#this is the code to detect those who t answered in a pattern.
colnames(fsir1.1)
library(careless)
#this is the long process of identifying long patterns of answers. I made sure to
#look into patterns in every scale separately, and those with 3 or more patterns
#were screened, alongside those with two who's response time was below 5 minutes.
#the full list of IDs to remove appears after the excel extraction codes.
fsir1.1$carelessLong <- longstring(fsir1.1)
#checked long patterns of answers-over all the questionnaire.
#outliers omission based on careless long
boxplot(fsir1.1$carelessLong)$out
#i'm creating subs for each scale, to measure careless long on each scale
#separately. the rational behind this - if a scale has 5 items, and the longest pattern for a respondent is 5.
fsir1.2 <- fsir1.1
#NOT APPLICABLE FOR THIS VERSION:
```
```{r 2more}
colnames(fsir1.2)
fsir6 <- subset(fsir1.2[,-c(3:5)])
```
##SECOND WAVE DATA CLEANING
```{r 2Cleaning 2}
library(rio)
library(foreign)
fsir2w <- import("C:/Everything R/DATA TRIALS - FSIR/Effects of Framing Counter Stereotypes - Replication Materials/r-project-template-based/Suprise Experiments/Data/lfsirb.sav",
to.data.frame = TRUE, stringsAsFactors = TRUE, header = TRUE)
fsir2w <- subset(fsir2w, userID!="")
fsir2w <- fsir2w[!duplicated(fsir2w$userID),]
table(fsir2w$Progress) #those who have progress rate of less than 58% didn't get to the first reading question.
#make one condition var.
colnames(fsir2w)
fsir2w$FL_7_DO_IDENT <- replace(fsir2w$FL_7_DO_IDENT,
fsir2w$FL_7_DO_IDENT==1, 2)
fsir2w$FL_7_DO_EXPLICIT <- replace(fsir2w$FL_7_DO_EXPLICIT,
fsir2w$FL_7_DO_EXPLICIT==1, 3)
fsir2w$FL_7_DO_Control1 <- replace(fsir2w$FL_7_DO_Control1,
fsir2w$FL_7_DO_Control1==1, 4)
#FL_7_DO_NOIDENT remainf as 1.
fsir2w$cond <- dplyr::coalesce(fsir2w$FL_7_DO_NOT_IDENT,
fsir2w$FL_7_DO_IDENT,
fsir2w$FL_7_DO_EXPLICIT,
fsir2w$FL_7_DO_Control1)
#make separate conds vars into one factor.
#now we clean all those who failed reading Qs.
#we start by making all the conditions' separate reading Qs into one var.
#since there were 4 block of conditions, 3 reading Qs, and 2 chance for each Q,
#there is a lot to condense.
#we start with all the 1st chance Qs (Q1a, Q2a, Q3a).
#mikraa:
#anything with T = not identified condition
#anything with B = identified condition
#anything with S = explicit surprise condition
#anything with C = control condition
colnames(fsir2w)
library(dplyr)
library(tidyr)
fsir2w <- subset(fsir2w, select = -c(159:231, 1:5, 7:18,
20:23, 25:28, 31:34, 36:39, 41:44, 47:50,
52:55, 57:60, 63:66, 68:71, 73:76, 79:82,
85:88, 142:144, 149))
#would need this in the full-scale experiment.
fsir2w$Q1a <- dplyr::coalesce(fsir2w$TReadingQ1a,
fsir2w$BReadingQ1a,
fsir2w$SReadingQ1a,
fsir2w$CReadingQ1a) #making all the readings
#1 into 1 var
fsir2w <- fsir2w %>% relocate(Q1a, .before = TReadingQ1a)
#relocating key var to better work with it and the others.
fsir2w$Q2a <- dplyr::coalesce(fsir2w$TReadingQ2a,
fsir2w$BReadingQ2a,
fsir2w$SReadingQ2a,
fsir2w$CReadingQ2a)
fsir2w <- fsir2w %>% relocate(Q2a, .after = Q1a)
#relocating key vars.
#there is no Q3a to use
fsir2w$Q3a <- dplyr::coalesce(fsir2w$CReadingQ3a)
fsir2w <- fsir2w %>% relocate(Q3a, .after = Q2a)
#now 2nd chances would be reduced into 1 item each, and relocated (Q1b, Q2b, Q3b).
fsir2w$Q1b <- dplyr::coalesce(fsir2w$TReadingQ1b,
fsir2w$BReadingQ1b,
fsir2w$SReadingQ1b,
fsir2w$CReadingQ1b)
fsir2w <- fsir2w %>% relocate(Q1b, .after = Q1a)
fsir2w$Q2b <- dplyr::coalesce(fsir2w$TReadingQ2b,
fsir2w$BReadingQ2b,
fsir2w$SReadingQ2b,
fsir2w$CReadingQ2b)
fsir2w <- fsir2w %>% relocate(Q2b, .after = Q2a)
#there is no Q3a to use
fsir2w$Q3b <- dplyr::coalesce(fsir2w$CReadingQ3b)
fsir2w <- fsir2w %>% relocate(Q3b, .after = Q3a)
#get rid of the unnecessary reading Qs columns.
colnames(fsir2w)
fsir2w <- subset(fsir2w, select = -c(9:26))
#now everyone who answered wrong, will get a zero.
fsir2w$Q1a[fsir2w$Q1a!=3] <- 0
fsir2w$Q1b[fsir2w$Q1b!=3] <- 0
fsir2w$Q2a[fsir2w$Q2a!=2] <- 0
fsir2w$Q2b[fsir2w$Q2b!=2] <- 0
fsir2w$Q3a[fsir2w$Q3a!=2] <- 0
fsir2w$Q3b[fsir2w$Q3b!=2] <- 0
#make a var for the sum of reading Qs scores.
fsir2w$F.P <- rowSums(fsir2w[,c("Q1a",
"Q1b",
"Q2a",
"Q2b",
"Q3a",
"Q3b")],na.rm = TRUE)
#Making all the wrong response to the reading Qs equal to 0,
library(psych)
table(fsir2w$F.P, fsir2w$cond)
fsir3w <- subset(fsir2w, cond==4 & F.P==7 | cond==3 & F.P==5 |
cond==2 & F.P==5| cond==1 & F.P==5)
```
```{r 2attcheck 2nd wave}
#from now on, there are only those who were fairly attentive.
#now we screen those who failed attention checks.
fsir3.1w <- subset(fsir3w, attcheck1==2 | is.na(attcheck1))
#this takes both those who were right, and those who didn't see the Q-from
#the control group.
fsir3.2w <- subset(fsir3.1w, attcheck2==5 | is.na(attcheck2))
###NEXT: TIME OF RESPONSE/CARELESSLONG###
```
```{r 2careless 2nd wave}
fsir3.4w <- subset(fsir3.2w, userID!="")
table(fsir3.4w$cond)
fsir4w <- fsir3.4w
```
```{r 2 2w normality and outliers}
### GENERAL DESRIPTION ###
library(report)
library(dplyr)
library(sjPlot)
library(apaTables)
library("writexl")
#######CHANGE NAME OF DEMOGRAPHIC COLUMNS#######
colnames(fsir4w)
colnames(fsir4w)[61] <- "Age2"
colnames(fsir4w)[62] <- "Sex2"
colnames(fsir4w)[63] <- "Region2"
colnames(fsir4w)[64] <- "MaritalS2"
colnames(fsir4w)[65] <- "Edu2"
colnames(fsir4w)[66] <- "Income2"
colnames(fsir4w)[67] <- "NewsConsumption2"
colnames(fsir4w)[68] <- "PoliticalInterest2"
colnames(fsir4w)[69] <- "relig2"
colnames(fsir4w)[2] <- "PolOr2"
colnames(fsir4w)[28] <- "attcheck1b"
fsir7.1 <- subset(fsir4w[, c(2, 9:69, 73:74)])
```
```{r 2MERGE FILES}
#the purpose here is to remove outliers for each condition separately, seeing
#every condition as a unite.
#INNER JOIN
lfsir <- merge(fsir7.1, fsir6, by = "userID")
#export(lfsir, "C:/Everything R/DATA TRIALS - FSIR/LFSIR/lfsir_full.recon14112022.sav")
###DO NOT TOUCH ANYTHING ABOVE.
#CLEAN.
lfsir <- subset(lfsir[-c(104), ] ) #remove duplicate with ID #910f4390a1598e5c6041973e643208c0
colnames(lfsir)
```
```{r remove exess dfs}
#export(lfsir2, "C:/Everything R/DATA TRIALS - FSIR/Replication materials/REP/check #knit/lfsir_no_outs.recon14112022.sav")
toremove <- grep("^lfsir|^collect1$", ls(),
invert = TRUE,
value = TRUE)
rm(list = c(toremove, "toremove"))
colnames(collect1)
colnames(lfsir)
```
```{r merge collections}
library(ltm)
lfsirfull <- subset(lfsir, select = c(1:21, 23:52, 55:64, 67:105, 107:144, 146:150))
collect2.m <- subset(collect1, select = -c(40, 79, 86, 136, 137, 142, 150))
fsir <- rbind(collect2.m, lfsirfull)
fsir <- fsir[!duplicated(fsir$userID),]
fsir <- subset(fsir, PolOr2<=7)
colnames(fsir)
fsir$heterogeneity_4 <- 7-fsir$heterogeneity_4
fsir$heterogeneity_5 <- 7-fsir$heterogeneity_5
cronbach.alpha(fsir[,112:116], na.rm = TRUE)
fsir$homogeneity <- (fsir$heterogeneity_1+
fsir$heterogeneity_2 +
fsir$heterogeneity_3 +
fsir$heterogeneity_4 +
fsir$heterogeneity_5)/5
colnames(fsir)
fsir <- fsir %>% relocate(attcheck2, .after = competence_4)
cronbach.alpha(fsir[,122:124], na.rm = TRUE)
fsir$SDA <- (fsir$SDA_1 +
fsir$SDA_2 +
fsir$SDA_3)/3
#create the var.
table(fsir$cond)
#reorder cond levels, and rename:
fsir$cond <- factor(fsir$cond, levels=c('4', '1', '2', '3'))
levels(fsir$cond) <- c("Control", "No Surprise-No Validation", "Insinuated surprise no validation", "Explicit Surprise validation")
fsir <- plyr::rename(fsir, replace =
c("thermomerer_A" = "thermometer_A"))
rm(list = ls()) # clean the global environment
cat ("\014")    #clean the R console
#import file named fsir from computer into R. The file already has meaningful
#names, scales were checked, and all unnecessary vars were removed.
library(rio)
library(foreign)
fsir <- import("C:/Everything R/DATA TRIALS - FSIR/Effects of Framing Counter Stereotypes - Replication Materials/r-project-template-based/Suprise Experiments/Data/gen_data.sav",
to.data.frame = TRUE, stringsAsFactors = TRUE, header = TRUE)
fsir <- subset(fsir, uid!="")
fsir <- fsir[!duplicated(fsir$uid),]
library(haven)
#fsir <- read_sav("Data/gen_data.sav")
#remove test responses:
fsir <- subset(fsir, fsir$uid!="4561981")
fsir <- subset(fsir, fsir$uid!="1525788")
fsir <- subset(fsir, fsir$uid!="105513718")
fsir <- subset(fsir, fsir$uid!="105514073")
fsir <- subset(fsir, fsir$uid!="105512424")
knitr::opts_chunk$set(echo = TRUE)
```
```{r cleaning 1}
##SECOND WAVE DATA CLEANING
#make one condition var.
colnames(fsir)
fsir$FL_7_DO_BEHAVIOR <- replace(fsir$FL_7_DO_BEHAVIOR,
fsir$FL_7_DO_BEHAVIOR==1, 2)
fsir$FL_7_DO_TRAITS <- replace(fsir$FL_7_DO_TRAITS,
fsir$FL_7_DO_TRAITS==1, 3)
fsir$FL_7_DO_ATTITUDES <- replace(fsir$FL_7_DO_ATTITUDES,
fsir$FL_7_DO_ATTITUDES==1, 4)
#FL_7_DO_Control1 remains as 1.
fsir$cond <- dplyr::coalesce(fsir$FL_7_DO_Control1,
fsir$FL_7_DO_BEHAVIOR,
fsir$FL_7_DO_TRAITS,
fsir$FL_7_DO_ATTITUDES)
#make separate conds vars into one factor.
fsir$cond <- as.factor(fsir$cond)
is.factor(fsir$cond)
levels(fsir$cond) <- c("Control", "No Surprise-No Validation", "Insinuated Surprise No Validation", "Explicit Surprise Validation")
#now we clean all those who failed reading Qs.
#mikraa:
#anything with T = not identified condition
#anything with B = identified condition
#anything with S = explicit surprise condition
#anything with C = control condition
colnames(fsir)
library(dplyr)
library(tidyr)
fsir2w <- subset(fsir, select = -c(170:242, 1:5, 7:17,
22:25, 27:30, 33:36, 38:41, 43:46, 49:52,
54:57, 59:62, 65:68, 70:73, 75:78, 81:84,
87:90))
colnames(fsir2w)
table(fsir2w$BReadingQ1a) #162 ANSWERS
table(fsir2w$TReadingQ1a) #160
table(fsir2w$AReadingQ1a) #162
table(fsir2w$CReadingQ1a) #177
#leaving only participants who were assigned to a condition.
fsir2w <- subset(fsir2w, cond!="")
#661 STARTED ANSWERING THE QUESTIONNAIRE.
fsir2w <- subset(fsir2w,
BReadingQ1b==3 | TReadingQ1b==3 | AReadingQ1b==3 | CReadingQ1b==3 |
BReadingQ1a==3 | TReadingQ1a==3 | AReadingQ1a==3 | CReadingQ1a==3 |
BReadingQ2b==2 | TReadingQ2b==2 | AReadingQ2b==2 | CReadingQ2b==2 |
BReadingQ2a==2 | TReadingQ2a==2 | AReadingQ2a==2 | CReadingQ2a==2 |
CReadingQ3a==2 | CReadingQ3b==2)
#make subset to continue working. it is enough to know who failed attcheck 2, to remove those
#who failed attcheck 1 (without excluding control participants who did not get attcheck 1).
fsir2w <- subset(fsir2w, attcheck2==5)
###NEXT: TIME OF RESPONSE/CARELESSLONG###
```
```{r careless }
library(ggplot2)
library(ggpubr)
#last screenings are for carelesslong and time of response.
colnames(fsir2w)
class(fsir2w$Duration__in_seconds_)
#the var is already numeric, which is what we need to proceed. if for some
#reason it isn't, use the code below by removing the # sign.
fsir2w$DuraMin <- fsir2w$Duration__in_seconds_/60
#make the duration in minutes
#time outliers:
boxplot(fsir2w$DuraMin)$out
boxplot(DuraMin ~ cond, fsir2w)$out
Q <- quantile(fsir2w$DuraMin, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(fsir2w$DuraMin)
up <-  Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Range
fsir3.4w <- subset(fsir2w, fsir2w$DuraMin > (Q[1] - 1.5*iqr) & fsir2w$DuraMin < (Q[2]+1.5*iqr))
table(fsir3.4w$cond, fsir3.4w$PolOr)
######################
#change the names of the manipilation check, to be indicative.
colnames(fsir3.4w)[colnames(fsir3.4w) == "mc_appreciation"] <- "mc_surprise"
colnames(fsir3.4w)[colnames(fsir3.4w) == "ManipCheck_6"] <- "mc_appreciation"
#manipulation check for pride - by cond
plot12 <- ggplot(fsir3.4w, aes(cond, mc_pride)) +
geom_violin(aes(color = cond)) + geom_boxplot(width = 0.2, outlier.shape = NA) + theme(axis.text.x = element_text(size = 7)) +
stat_summary(fun='mean', geom='point', size=2, col='red')+
stat_summary(fun = mean, geom = "text", col = "#661100",     # Add text to plot
vjust = 2, size=2.85, aes(label = (round(..y.., digits = 2))))+
scale_color_manual(values = c("#000000", "#0072B2", "#999999", "#56B4E9", "#009E73", "#D55E00")) +
xlab("Condition")+
ylab("mc pride")
plot12
#manipulation check for surprise - by cond
plot12 <- ggplot(fsir3.4w, aes(cond, mc_surprise)) +
geom_violin(aes(color = cond)) + geom_boxplot(width = 0.2, outlier.shape = NA) + theme(axis.text.x = element_text(size = 7)) +
stat_summary(fun='mean', geom='point', size=2, col='red')+
stat_summary(fun = mean, geom = "text", col = "#661100",     # Add text to plot
vjust = 2, size=2.85, aes(label = (round(..y.., digits = 2))))+
scale_color_manual(values = c("#000000", "#0072B2", "#999999", "#56B4E9", "#009E73", "#D55E00")) +
xlab("Condition")+
ylab("mc surprise")
plot12
#manipulation check for  - by cond
plot12 <- ggplot(fsir3.4w, aes(cond, mc_discontempt)) +
geom_violin(aes(color = cond)) + geom_boxplot(width = 0.2, outlier.shape = NA) + theme(axis.text.x = element_text(size = 7)) +
stat_summary(fun='mean', geom='point', size=2, col='red')+
stat_summary(fun = mean, geom = "text", col = "#661100",     # Add text to plot
vjust = 2, size=2.85, aes(label = (round(..y.., digits = 2))))+
scale_color_manual(values = c("#000000", "#0072B2", "#999999", "#56B4E9", "#009E73", "#D55E00")) +
xlab("Condition")+
ylab("mc contempt")
plot12
#manipulation check for  - by cond
plot12 <- ggplot(fsir3.4w, aes(cond, mc_appreciation)) +
geom_violin(aes(color = cond)) + geom_boxplot(width = 0.2, outlier.shape = NA) + theme(axis.text.x = element_text(size = 7)) +
stat_summary(fun='mean', geom='point', size=2, col='red')+
stat_summary(fun = mean, geom = "text", col = "#661100",     # Add text to plot
vjust = 2, size=2.85, aes(label = (round(..y.., digits = 2))))+
scale_color_manual(values = c("#000000", "#0072B2", "#999999", "#56B4E9", "#009E73", "#D55E00")) +
xlab("Condition")+
ylab("mc appreciation")
plot12
#compare means of manipulation check - mainly mc_surprise
comp1 <- compare_means(
formula = mc_appreciation ~ cond,
fsir3.4w,
method = "anova",
paired = TRUE
)
comp1
comp1 <- compare_means(
formula = mc_surprise ~ cond,
fsir3.4w,
method = "anova",
paired = TRUE
)
comp1
comp1 <- compare_means(
formula = mc_discontempt ~ cond,
fsir3.4w,
method = "anova",
paired = TRUE
)
comp1
#no differences between conditions in read emotions like contempt or appreciation (positive and negative), but there are differences as expected when it comes to reading surprise from the text.
#####outliers
boxplot(Age ~ cond, fsir3.4w)$out #no outs
boxplot(PolInterest ~ cond, fsir3.4w)$out #no outs
boxplot(PolOr ~ cond, fsir3.4w)$out #no outs, looks different, but no sig diffs.
boxplot(Edu ~ cond, fsir3.4w)$out #no outs, looks different, but no sig diffs.
boxplot(Income ~ cond, fsir3.4w)$out #no outs, looks different, but no sig diffs.
boxplot(NewsConsum ~ cond, fsir3.4w)$out #no outs.
table(fsir3.4w$cond)
```
```{r scales 2nd wave}
#this chunk is for verifying and building the following scales:
#surprise- stays 1 item "surprise_1".
#represent- stays 1 item "represent_R_1".
#chacee - stays 1 item ""chance_acheive".
#sdr
#insim
#backlash
#rethink
#homogeneity
#competence
#sda
#openness to change
#willingness to change
#capability to change
#media credibility
#self definition as feminist
#support for feminist views
library(ltm)
library(psych)
###HETEROGENEITY OF OUTGROUP###
cronbach.alpha(fsir3.4w[, 57:61])
fsir3.4w$homogeneity <- (fsir3.4w$homogen_1 +
fsir3.4w$homogen_2 +
fsir3.4w$homogen_3 +
fsir3.4w$homogen_4 +
fsir3.4w$homogen_5)/5
#create the var.
###SDA###
colnames(fsir3.4w)
fsir3.4w <- fsir3.4w %>% relocate(attcheck2, .after = competence_4)
cronbach.alpha(fsir3.4w[, 67:69])
fsir3.4w$SDA <- (fsir3.4w$SDA_1 +
fsir3.4w$SDA_2 +
fsir3.4w$SDA_3)/3
#create the var.
```
```{r 2w less vars}
colnames(fsir3.4w)
fsir7.1 <- subset(fsir3.4w[, c(3, 5, 24:39, 41:65, 67:93, 95:98, 101:105)])
```
```{r extraction of file}
#export datasets
library(rio)
library(foreign)
library(datasets)
library(careless)
fsir7.1$RCL <- ifelse(fsir7.1$PolOr<4, '1', ifelse(fsir7.1$PolOr>4, '3', '2'))
fsir7.1$RCL <- as.numeric(fsir7.1$RCL)
is.numeric(fsir7.1$RCL)
table(fsir7.1$RCL, fsir7.1$PolOr)
table(fsir7.1$cond)
toremove <- grep("^fsir7.1", ls(),
invert = TRUE,
value = TRUE)
rm(list = c(toremove, "toremove"))
